---
title: "BME 4550_Assignment 6"
author: "Kelsie Reinaltt"
date: "10/18/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(UsingR)
library(tidyverse)
library(contrast)
library(downloader)
head(father.son)
```

# Chapter: Matrix Algebra
# Pages 146-147 Exercises


## Question 1 
####The average height of the sons is 68.68407, as shown below.
```{r}
mean(father.son$sheight)

```


## Question 2
```{r}
fatherht<-round(father.son$fheight,0)
fathersonht<-cbind(fatherht,father.son)

suppressMessages(library(dplyr))
sonht<-filter(fathersonht,fatherht==71) %>% select(sheight) %>% unlist
mean(sonht)
```


## Question 3
#### C is not a linear model because b^t is not a linear combination.

## Question 4
#### D is the correct answer because people of the same height may have different fat masses. 

# Page 151 Exercises

## Question 1
#### The entry in this position is 225. 
```{r}
X = matrix(1:1000,100,10)
X[25,3]
```


## Question 2

The sum is 105. 

```{r}
x=1:10
M<-cbind(x,2*x,3*x,4*x,5*x)
sum(M[7,])
```


##Question 3
#### Just by looking at the data, I can tell that the answer is NOT D because it onoly has 2 columns. Actually creating the other matrices looks like this: 

#### After looking at all of these, I can tell that the B matrix is the only one with a third  column that has multiples of 3. 
```{r}
matrix(1:60,20,3)
matrix(1:60,20,3,byrow=TRUE)
x=11:20; rbind(x,2*x,3*x)
x=1:40; matrix(3*x,20,2)
```


# Page 157 Exercises 

##Question 1

#### The second will not be equal to X. B

## Question 2
```{r, eval = FALSE}
3a + 4b - 5c + d = 10
2a + 2b + 2c - d = 5
a - b + 5c - 5d = 7
5a + d = 4
```

```{r}
X <- matrix(c(3,2,1,5,4,2,-1,0,-5,2,5,0,1,-1,-5,1),4,4)
y <- matrix(c(10,5,7,4),4,1)
solve(X)%*%y
```

#### c is the 3rd row (there is only one column), so it is equal to -0.9949558. ** -1.5 answer is -.8849 (you wrote it incorrectly)

## Question 3

```{r, eval = FALSE}
a <- matrix(1:12, nrow=4)
b <- matrix(1:15, nrow=3)
```


```{r}
a <- matrix(1:12, nrow=4)
b <- matrix(1:15, nrow=3)
c<-a %*% b
c[3,2]
```


## Question 4

```{r}
sum(a[3,] * b[,2])
```
 

# Pages 165 Exercises

## Question 1

```{r, eval = TRUE}
X <- matrix(c(1,1,1,1,0,0,1,1),nrow=4)
rownames(X) <- c("a","a","b","b")
X
```


```{r, eval = FALSE}
beta <- c(5, 2)
```


```{r}
X <- matrix(c(1,1,1,1,0,0,1,1),nrow=4)
rownames(X) <- c("a","a","b","b")

beta <- c(5, 2)

fitted = X %*% beta

fitted[ 1:2, ]
```

## Question 2

```{r}
fitted = X %*% beta
fitted[ 3:4, ]
```

## Question 3

```{r, eval = FALSE}
X <- matrix(c(1,1,1,1,1,1,0,0,1,1,0,0,0,0,0,0,1,1),nrow=6)
rownames(X) <- c("a","a","b","b","c","c")
X
```


```{r, eval = FALSE}
beta <- c(10,3,-3)
```



```{r}
fitted = X %*% beta

fitted[ 3:4, ]
```

## ** -2.5 answer is 13 

## Question 4

```{r}
fitted = X %*% beta

fitted[ 3:4, ]
```

# Chapter: Linear Models
# Pages 166-168 Questions

## Question 1
```{r}
B <- 1000
g = 9.8
h0 = 56.67
v0 = 0
n = 25
tt = seq(0,3.4,len=n)
tt
y = h0 + v0 *tt - 0.5* g*tt^2 + rnorm(n,sd=1)
X = cbind(1,tt,tt^2)
A = solve(crossprod(X))%*%t(X)

betahat<-replicate(B,{
  y <- h0 + v0*tt  - 0.5*g*tt^2 + rnorm(n,sd=1)
  betahats <- A%*%y
  return(betahats[3])
})
head(betahat)
round(mean(betahat),1)
sd(betahat)
```
#### The code above finds the cross product of S by S and compares it to the known equation. The mean dsitribution of betahat displays a value of -4.9, which is essentially (A %*% y)[3] which when multiplied by -2 is 9.8. Therefore g = -2 * (A %*% y)[3]

## Question 2 
```{r}

B <- 100000
g = 9.8
h0 = 56.67
v0 = 0
n = 25
tt = seq(0,3.4,len=n)
tt
y = h0 + v0 *tt - 0.5* g*tt^2 + rnorm(n,sd=1)
X = cbind(1,tt,tt^2)
A = solve(crossprod(X))%*%t(X)

betahat<-replicate(B,{
  y <- h0 + v0*tt  - 0.5*g*tt^2 + rnorm(n,sd=1)
  betahats <- A%*%y
  return(betahats[3])
})
head(betahat)
round(mean(betahat),1)
sd(betahat)

```
#### The standard error of this estimate is 0.2151166. ** -2.5 SE should be .429


## Question 3
```{r}
x = father.son$fheight
y = father.son$sheight
n = length(y)
N <- 50
B <-10000
betahat <- replicate(B,{
  index <- sample(n,N)
  sampledat <- father.son[index,]
  x <- sampledat$fheight
  y <- sampledat$sheight
  lm(y~x)$coef
  })
betahat <- t(betahat)
sd(betahat)

```
#### The standard deviation for the slope estimate appears to be within 17.5-17.7 inches range ** -2.5 SD should be .124

## Question 4 

```{r}
mean( (betahat[,1]-mean(betahat[,1] ))* (betahat[,2]-mean(betahat[,2])))
```
The covariance appears to be closes to 0. 

## ** -2.5 answer is C

# Pages 177-178 Questions

## Question 1
```{r}
condition <- factor(c("treated","treated","treated","treated","treated","treated","control","control","control","control","control","control"))
day<- factor(c("A","A","B","B","C","C","A","A","B","B","C","C"))

table(condition,day)
model.matrix(~day + condition)
```

A) ~ day + condition

# Pages 183-184 Questions

## Question 1
#### the element in the first row and first column is 12.
```{r}
X <- cbind(rep(1,5 + 7),rep(c(0,1),c(5, 7)))
t(X) %*% (X)
```

## Question 2
#### the other entries (other than element in row 1 column 1) are all the number 7 
```{r}
X <- cbind(rep(1,5 + 7),rep(c(0,1),c(5, 7)))
t(X) %*% (X)
```


# Pages 193-194 Questions

## Question 1

```{r}
library(UsingR)

x = father.son$fheight
y = father.son$sheight

n = length(y)
N = 50

set.seed(1)
index = sample(n,N)

sampledat = father.son[index,]
x = sampledat$fheight
y = sampledat$sheight

betahat = lm(y~x)$coef
fit <- lm(y ~ x)
fit$fitted.values
e<-y-fit$fitted.values
sum(e^2)
```
Sum of the squared residuals is 256.2152

## Question 2

Sigma squared = SSR / 48 

```{r}
256.2152/48
```
Sigma squared is equivalent to 5.337817


## Question 3 

```{r}
X = cbind(rep(1,N), x)
solve(t(X) %*% X)[1,1]

```
XT %*% X [1,1] = 11.30275

## Question 4
```{r}
sqrt(diag(solve(t(X) %*% X)) * (256.2152/48))

```
#### The standard error for the slope is 0.1141966. 

# Pages 224-226 Questions

## Question 1

```{r}
species <- factor(c("A","A","B","B"))
condition <- factor(c("control","treated","control","treated"))
model.matrix(~ species + condition)
y = rnorm(4)

fit = lm(y ~ species + condition)

contrast(fit, list(species="B",condition="control"), list(species="A",condition="treated"))$X
```

#### The contrast vector should be 0 -1 1. ** -2.5 contrast vector is 0 1 -1

## Question 2

```{r}

url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/spider_wolff_gorb_2013.csv"
filename <- "spider_wolff_gorb_2013.csv"
library(downloader)
if (!file.exists(filename)) download(url, filename)
spider <- read.csv("spider_wolff_gorb_2013.csv", skip=1)
fitTL <- lm(friction ~ type + leg, data=spider)
summary(fitTL)
(coefs <- coef(fitTL))
L4vsL2 <- contrast(fitTL,list(leg="L4",type="pull"),list(leg="L2",type="pull"))
L4vsL2$testStat
```

#### t = 2.451974

## Question 3

```{r}
X <- model.matrix(~ type + leg, data=spider)
(Sigma <- sum(fitTL$residuals^2)/(nrow(X) - ncol(X)) * solve(t(X) %*% X))
C <- matrix(c(0,0,-1,0,1),1,5)
Sigma[3,5]
```
Cov(beta-hat_L4, beta-hat_L2) = 0.0006389179

## Question 4
```{r}
spider$log2friction <- log2(spider$friction)
head(spider)
boxplot(log2friction ~ type*leg, data=spider)
fitln <- lm(log2friction ~ type*leg, data=spider)
summary(fitln)
```
#### Typepush-legL4 has a tstatistic value of -3.689. As this is a large value, we reject the null hypothesis that push vs. pull effect on
#### log2(friction) is the same in L4 as in L1.

## Question 5
```{r}
anova(fitln)
```
#### The f-statistic is 10.701. Thus we reject the null hypothesis that the push vs. pull effect on log2(friction) is the same for all leg pairs.

## Question 6

```{r}
contrast(fitln, list(type="pull",leg="L2"), list(type="pull",leg="L1"))
coef(fitln)["legL2"]
```
#### The L2 vs L1 estimate for pull is 0.3468125 

## Question 7

```{r}
contrast(fitln, list(type="push",leg="L2"), list(type="push",leg="L1"))
coef(fitln)["legL2"] + coef(fitln)["typepush:legL2"]
```
#### The L2 vs L1 estimate for push is 0.4464843

# Pages 231-232 Questions

## Question 1

```{r}
m = matrix(c(1,1,1,1,0,0,1,1,0,1,0,1,0,0,0,1),4,4)
m
qr(m)$rank
```
#### As the rank of the E matrix is equal to the number of columns, so all of the columns are independent.Therefore E does not have the issue of collinearity


## Question 2

```{r}

sex <- factor(rep(c("female","male"),each=4))
trt <- factor(c("A","A","B","B","C","C","D","D"))

X <- model.matrix( ~ sex + trt)

qr(X)$rank

Y <- 1:8

makeYstar <- function(a,b) Y - X[,2] * a - X[,5] * b


fitTheRest <- function(a,b) {
  Ystar <- makeYstar(a,b)
  Xrest <- X[,-c(2,5)]
  betarest <- solve(t(Xrest) %*% Xrest) %*% t(Xrest) %*% Ystar
  residuals <- Ystar - Xrest %*% betarest
  sum(residuals^2)
}
fitTheRest(1,2)


```
 
#### Sum of squared residuals when male coefficient is 1, and the D coefficient is 2, and the other coefficients are fit using the linear model solution  = 11. 

## Question 3
```{r}
expand.grid(1:3,1:3)

betas = expand.grid(-2:8,-2:8)
rss = apply(betas,1,function(x) fitTheRest(x[1],x[2]))
themin= min(rss)
betas[which(rss==themin),]


```
#### As there is no single minimum, all of the above are the smallest Least Square Residuals. ** -2.5 RSS is 2

