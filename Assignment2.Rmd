---
title: "Assignment2"
author: "Kelsie Reinaltt"
date: "9/6/2018"
output: html_document
---

# 5.2.4

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(nycflights13)
library(tidyverse)
library(ggbeeswarm)
```

# Question 1.1

```{r}
filter(flights, arr_delay >= 120)
```

# Question 1.2
```{r}
filter(flights, dest %in% c("IAH", "HOU"))
```

# Question 1.3
```{r}
filter(flights, carrier %in% c("AA", "DL", "UA"))
```

# Question 1.4
```{r}
filter(flights, month >= 7, month <= 9)
```

# Question 1.5
```{r}
filter(flights, dep_delay <= 0, arr_delay > 120)
```

# Question 1.6
```{r}
filter(flights, dep_delay >= 60, dep_delay - arr_delay > 30)
```

# Question 1.7
```{r}
filter(flights, dep_time <= 600 | dep_time == 2400)
```

# Question 2
# Between is a shorter, faster way of testing two inequalities at once: it tests if its first argument is greater than or equal to its second, and less than or equal to its third.

# Question 3
### 8255 flights have missing departure times. 8255 flights have missing departure delays. 8713 flights have missing arrival times. 9430 flights have missing arrival delays. 9430 flights have missing air time.
### The flights with missing data may indicate that the flights in question may have never departed or arrived. The flights that departed but never arrived may have been rerouted. The missing data may also be a result of lost data. 
```{r}
summary(flights)
```

# Question 4
### Anything to the 0th power results in 1. Therefore, NA ^ 0 = 1, so the values is 1 and is not missing.
### NA | TRUE is not missing because the expresion evaluates to TRUE. If the value is TRUE, the value is not missing.
### FALSE & NA is not missing because the expression evaluates to FALSE. If the value is FALSE, then the value is not missing.
### Expressions involving NA will genearlly follow the universal rules and therefore no longer be missing (ex: TRUE|anything = TRUE, FALSE & anything = FALSE). However, there exist cases in which the universal rules have exceptions, such as NA * 0 = NaN. In such cases, the value remains missing, or NA.

# 5.3.1

# Question 1
```{r}
arrange(flights, desc(is.na(dep_time)), dep_time)
```

# Question 2
```{r}
arrange(flights, desc(dep_delay))
```

# Question 3
```{r}
arrange(flights, air_time)
```

# Question 4
```{r}
arrange(flights, distance)
arrange(flights, desc(distance))
```


5.4.1

# Question 1
```{r}
select(flights, dep_time, dep_delay, arr_time, arr_delay)
select(flights, starts_with("dep_"), starts_with("arr_"))
```
# Question 2
### The duplicates will be ignrored, and the repeated variableis only included once. R Studio will take care of this with no error, warning, or message emitted.
```{r}
select(flights, year, month, month, day, year)
```

# Question 3
### The one_of() function select variables using a character vector rather than as unquoted variable names. Using this function makes it easier to programmatically generate character vectors with variable names than to generate unquoted variable names, which are easier to type.
```{r}
vars <- c("year", "month", "day", "dep_delay", "arr_delay")
```

# Question 4
### The code surprises me because it appears the variables are case-insensitive. By default, helper functions are insensitive to case. The default can be changed using the following code: ignore.case = FALSE
```{r}
select(flights, contains("TIME"))

```

#5.5.2

# Question 1
```{r}
# with integer division
mutate(flights,
       dep_time = (dep_time %/% 100) * 60 + (dep_time %% 100),
       sched_dep_time = (sched_dep_time %/% 100) * 60 + (sched_dep_time %% 100))

# with rounding operations
mutate(flights,
       dep_time = 60 * floor(dep_time/100) + (dep_time - floor(dep_time/100) * 100),
       sched_dep_time = 60 * floor(sched_dep_time/100) + (sched_dep_time - floor(sched_dep_time/100) * 100))
```

# Question 2
### Firstly, we notice that if arr_time is in clock format, but dep_time is in minutes-after-midnight format, as per the previous question, we get the wrong answer. Obviously converting arr_time to minutes-after-midnight solves this problem.
### Second, we find that some of the results of arr_time - dep_time are large negative numbers. This occurs when a flight sets off before midnight but arrives after it. We can deal with this by using modular arithmetic again (and assuming that no flights take off before midnight and land after midnight the day after.)
### Finally, we find that arr_time - dep_time can vary significantly from air_time.
```{r}
flights %>% 
  mutate(dep_time = (dep_time %/% 100) * 60 + (dep_time %% 100),
         sched_dep_time = (sched_dep_time %/% 100) * 60 + (sched_dep_time %% 100),
         arr_time = (arr_time %/% 100) * 60 + (arr_time %% 100),
         sched_arr_time = (sched_arr_time %/% 100) * 60 + (sched_arr_time %% 100)) %>%
  transmute((arr_time - dep_time) %% (60*24) - air_time)
```

# Question 3
### dep_time, sched_dep_time, and dep_delay may be related by the following equation: dep_time - sched_dep_time = dep_delay.


# Question 4
### Here, ties are handled by taking the minimum of tied values. If the three most delayed flights have the same delay times, then those 3 flights would be tied for 1st, not 2nd or 3rd. 
```{r}
mutate(flights,
       dep_delay_rank = min_rank(-dep_delay)) %>%
  arrange(dep_delay_rank) %>%
  filter(dep_delay_rank <= 10)
```

# Question 5
### The code returns [1]  2  4  6  5  7  9  8 10 12 11, which is mathematically equal to c(1 + 1, 2 + 2, 3 + 3, 1 + 4, 2 + 5, 3 + 6, 1 + 7, 2 + 8, 3 + 9, 1 + 10). When adding two vectors of different size, the smaller vector's values get cycled through again.
```{r}
1:3 + 1:10
```

# Question 6
### cos(x), sin(x), tan(x), acos(x), asin(x), atan(x), atan2(y, x), cospi(x), sinpi(x), tanpi(x).

# 5.6.7

# Question 1
### A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.
### A flight is always 10 minutes late.
### A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.
### 99% of the time a flight is on time. 1% of the time it’s 2 hours late.
### Which is more important: arrival delay or departure delay?

# Question 2
### Using "group_by"" and "summarize"" instead of count is more verbose, but it can be clearer, especially in more complex situations.
```{r}
not_cancelled <- filter(flights, !is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>%
  group_by(dest) %>%
  tally()

not_cancelled %>%
  group_by(tailnum) %>%
  summarise(n = sum(distance))
```

# Question 3
## The more relevant column is arr_delay. If a flight never departs, then it won’t arrive. A flight could also depart and not arrive if it crashes, or if it is redirected and lands in an airport other than its intended destination.

# Question 4
### There seems to be a correlation between canceled flights and average delays. Yes, it looks like the proportion of canceled flights is realted to the average delay.
```{r}
canceled_delayed <-
  flights %>%
  mutate(canceled = (is.na(arr_delay) | is.na(dep_delay))) %>%
  group_by(year, month, day) %>%
  summarise(prop_canceled = mean(canceled),
            avg_dep_delay = mean(dep_delay, na.rm = TRUE))

ggplot(canceled_delayed, aes(x = avg_dep_delay, prop_canceled)) +
  geom_point() +
  geom_smooth()
```

# Question 5
### Frontier Airlines (F9) has the worst delays.
### You can get part of the way to disentangling the effects of airports vs. carriers by comparing each flight’s delay to the average delay of destination airport. However, you’d really want to compare it to the average delay of the destination airport, after removing other flights from the same airline.
```{r}
flights %>%
  group_by(carrier) %>%
  summarise(arr_delay = mean(arr_delay, na.rm = TRUE)) %>%
  arrange(desc(arr_delay))
```
# Question 6
### The sort argument to count() sorts the results in order of n. You could use this anytime you would run count() followed by arrange().


# 5.7.1

# Question 1
### instead of operating over the entire data frame, the filtering functions operate within each group when combined with grouping

# Question 2
### The are multiple planes that have nover been recorded as "on-time", as shown in the table below:
```{r}
flights %>%
  filter(!is.na(arr_delay)) %>%
  mutate(canceled = is.na(arr_time),
         late = !canceled & arr_delay > 0) %>%
  group_by(tailnum) %>%  
  summarise(on_time = mean(!late)) %>%
  filter(min_rank(on_time) <= 1)
```

#Question 3
### Based on the data and table shown, its filghts earlier in the day tend to have less delays than the later flights. It is best to take earlier flight to avoid delays. 
```{r}
flights %>%
  group_by(hour) %>%
  summarise(arr_delay = mean(arr_delay, na.rm = TRUE)) %>%
  arrange(arr_delay)
```

# Question 4
```{r}
flights %>%
  filter(!is.na(arr_delay), arr_delay > 0) %>%  
  group_by(dest) %>%
  mutate(arr_delay_total = sum(arr_delay),
         arr_delay_prop = arr_delay / arr_delay_total)
```

# Question 5
```{r}
### using lag() to explore how the delay of a flight is related to the delay of the immediately preceding flight

lagged_delays <- flights %>%
  arrange(origin, year, month, day, dep_time) %>%
  group_by(origin) %>%
  mutate(dep_delay_lag = lag(dep_delay)) %>%
  filter(!is.na(dep_delay), !is.na(dep_delay_lag))


lagged_delays %>%
  group_by(dep_delay_lag) %>%
  summarise(dep_delay_mean = mean(dep_delay)) %>%
  ggplot(aes(y = dep_delay_mean, x = dep_delay_lag)) +
  geom_point() +
  geom_smooth() +
  labs(y = "Departure Delay", x = "Previous Departure Delay")

### summary of relationships in delays: 

lagged_delays %>%
  summarise(delay_diff = mean(dep_delay - dep_delay_lag), na.rm = TRUE)

```

# Question 6
```{r}
# super fast
not_cancelled %>% group_by(dest) %>%
    mutate(speed = distance / air_time) %>%
    arrange(-speed)

# shortest flight per destination
not_cancelled %>% group_by(dest) %>%
    filter(air_time == min(air_time)) %>%
    select(dest, min_air = air_time) %>%
    inner_join(flights, by = "dest") %>%
    mutate(relative_air = air_time / min_air) %>%
    arrange(-relative_air)
```

# Question 7
### ExpressJet Airlines flies to at least 2 carriers and flies to the most destinations.
```{r}
dest_2carriers <- flights %>%
  # keep only unique carrier,dest pairs
  select(dest, carrier) %>%
  group_by(dest, carrier) %>%
  filter(row_number() == 1) %>%
  # count carriers by destination
  group_by(dest) %>%
  mutate(n_carrier = n_distinct(carrier)) %>%
  filter(n_carrier >= 2)

carriers_by_dest <- dest_2carriers %>%
  group_by(carrier) %>%
  summarise(n_dest = n()) %>%
  arrange(desc(n_dest))
head(carriers_by_dest)
```

# Question 8
```{r}
flights %>%
  arrange(tailnum, year, month, day) %>%
  group_by(tailnum) %>%
  mutate(delay_gt1hr = dep_delay > 60) %>%
  mutate(before_delay = cumsum(delay_gt1hr)) %>%
  filter(before_delay < 1) %>%
  count(sort = TRUE)
```

# Chapter 7

# 7.3.4

# Question 1
### The x an y distributions are essentialy the same. It appears that large diamonds are found in less quanitity than smaller diamonds. Also, all three distributions have a bimodality, or two noticable peas in their data representation.
```{r}
diamonds %>%
  mutate(id = row_number()) %>%
  select(x, y, z, id) %>%
  gather(variable, value, -id)  %>%
  ggplot(aes(x = value)) +
  geom_density() +
  geom_rug() +
  facet_grid(variable ~ .)

```

# Question 2
### There are diamonds available with prices ranging from $1000 to $2000 on this graph, however there are no diamonds priceds around $1500 for this particular data.
```{r}
diamonds <- diamonds %>% filter(2 < y & y < 20 & 2 < x & 2 < z & z < 20)
ggplot(diamonds) + 
  geom_freqpoly(aes(x = price), binwidth = 10) +
  xlim(c(1000, 2000))
```

# Question 3
### There seems to be alot more diamonds of 1 carat and not as many 0.99 carrat. 1 is a more whole number than 0.99. Just like in grocery stores where items are mostly priced as $X.99 can have a pyschological effect on consumers, a 1 carat diamond may sound alot more enticing that 0.99 carat and therefore there are more 1 carat diamonds.
```{r}
diamonds %>% filter(carat == 0.99) %>% count()
diamonds %>% filter(carat == 1) %>% count()
```
# Question 4
### coord_cartesian() plots and cuts, while xlim() cuts and plots. So xlim() does not show the half bar.
```{r}
ggplot(diamonds) + 
  geom_histogram(aes(x = carat)) +
  coord_cartesian(xlim = c(0.97, 1.035))

ggplot(diamonds) + 
  geom_histogram(aes(x = carat)) +
  xlim(c(0.97, 1.035))
```

# 7.4.1

# Question 1
### In a histogram, they simply leave a gap in the distribution, as in the gap in the above histogram of price. For the barplot, the function removes the NA value.
```{r}
diamonds %>%
  ggplot(aes(price)) +
  geom_histogram(bins = 1000)
```

# Question 2
### na.rm ignores the "NA"s when calculating mean and sum.


# 7.5.1.1

# Question 1

```{r}
flights %>% 
  mutate(cancelled = is.na(dep_time) | is.na(arr_time)) %>% 
  ggplot() +
  geom_boxplot(aes(x = cancelled, y = dep_time))

flights %>% 
  mutate(cancelled = is.na(dep_time) | is.na(arr_time)) %>% 
  filter(cancelled) %>% 
  select(dep_time)
```

# Question 2
### Carat seems to be the most important variable when predicting the price of a diamond, therefore it is the most important variable. Carat and cut seem to have a negative correlation, indicating that higher weighted diamonds usually have a lower cut rating. Lower quality diamonds end up being more expensive because better cut has lower carat, which makes the price lower. 

```{r}
diamonds %>%
  mutate(cut = as.numeric(cut),
         color = as.numeric(color),
         clarity = as.numeric(clarity)) %>%
  select(price, everything()) %>%
  cor()


```

# Question 3
### Seems like the result is the same; but the call of the function seems more natural.

# Question 4
### While the boxplot only shows a few quantiles and outliers, the letter-value plot shows many quantiles.

# Question 5
### Violin plot is best to compare the density distribution across different categories.
```{r}
ggplot(diamonds) +
  geom_histogram(aes(x = price)) +
  facet_wrap(~cut)

ggplot(diamonds) +
  geom_freqpoly(aes(x = price)) +
  facet_wrap(~cut)

ggplot(diamonds) +
  geom_violin(aes(x = cut, y = price))

```

# Question 6
```{r}
ggplot(data = mpg) + 
  geom_jitter(mapping = aes(x = drv, y = displ))

library(ggbeeswarm)
ggplot(data = mpg) + 
  geom_beeswarm(mapping = aes(x = drv, y = displ), priority = 'ascending')
```

#7.5.2.1

# Question 1
### We can calculate the proportion of each cut within color, and vice versa.
```{r}
diamonds %>% count(color, cut) %>% group_by(color) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot() +
  geom_tile(mapping = aes(x = color, y = cut, fill = prop)) +
  labs(title = 'Distribution of cut within color')
```

# Question 2
###The plot is not easy to read because:
### 1. the color scale range makes it hard to distinguish and compare airports and months
### 2. there are empty cells, which denote missing values (no flights departed from the airport, different from averaged delayed in 0 minutes)
### 3. the x label is incorrect
### We will keep the NA cells for two reasons:
### 1. not ideal if we remove the entire row. The non-missing cells still represent data.
### 2. NA actually reflects that no flights departed in the origin airports in that particular month (which is odd, but that’s the data we are given). Let’s just assumme it means something.
```{r}
nycflights13::flights %>% group_by(dest, month) %>%
  summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot() +
  geom_tile(mapping = aes(x = month, y = dest, fill = avg_dep_delay))

nycflights13::flights %>% group_by(dest, month) %>%
  summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) %>%
  ungroup() %>%
  group_by(dest) %>%
  mutate(n_month = n())%>%
  ggplot() +
  geom_tile(mapping = aes(x = factor(month),
                          y = reorder(dest, n_month),
                          fill = avg_dep_delay)) +
  scale_fill_gradient2(low = 'yellow', mid = 'orange', high = 'red',
                       midpoint = 35)
```

# Question 3
### here are more levels in diamonds$color so it makes more sense to put the factor with more levels on the x-axis.
```{r}
diamonds %>% count(color, cut) %>% group_by(color) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot() +
  geom_tile(mapping = aes(x = cut, y = color, fill = prop)) +
  labs(title = 'Distribution of cut within color')


```

7.5.3.1

# Question 1
### Unlike geom_density(), geom_freqpoly() is a smoothered histogram, so the height of each polygon is affected by the number of observations in each group. Setting the cut_width too small will have too many categories. Some of the categories will have very few observations, resulting in polygons that are flat and close to the x-axis. Compare the cut_width of .2 and .4:
```{r}
diamonds %>% ggplot() +
  geom_freqpoly(mapping = aes(x = price,
                              color = cut_width(carat, .2)), bins = 30)
diamonds %>% ggplot() +
  geom_freqpoly(mapping = aes(x = price,
                              color = cut_width(carat, .4)), bins = 30)
diamonds %>% ggplot() +
  geom_freqpoly(mapping = aes(x = price,
                              color = cut_number(carat, 10)), bins = 30)
```

# Question 2
### Using geom_density() and partitioning by price with cut_width, it is not surprising to see that diamonds of higher carat are associated with higher price in general.
```{r}
diamonds %>% ggplot() +
  geom_density(mapping = aes(x = carat,
                             color = cut_width(price, 5000, boundary = 0)))
```

# Question 3
### The price distribution of very large diamonds are much more variable than the smaller diamonds. Perhaps other factors, such as cut, clarity, and color have heavier influence on the price of larger diamonds.
```{r}
diamonds %>% ggplot +
  geom_boxplot(mapping = aes(x = cut_number(carat, 10),
                             y = price)) +
  coord_flip()
```

# Question 4
```{r}

  diamonds %>% ggplot() +
  geom_boxplot(mapping = aes(x = cut, y = price,
                             color = cut_number(carat, 5)))

diamonds %>% mutate(carat_group = cut_number(carat, 10)) %>%
  group_by(cut, carat_group) %>%
  summarize(avg_price = mean(price)) %>%
  ggplot() +
  geom_tile(mapping = aes(x = cut, y = carat_group,
                          fill = avg_price))

diamonds %>% ggplot() +
  geom_bin2d(mapping = aes(x = carat, y = price)) +
  facet_grid(cut~.)
```

# Question 5
### In the first scatterplot, we can identity the outliers while at the same time observe the strong positive correlation between x and y. 

### Even though they look similarly, I believe the logical reasoning behind why scatterplot is superior in this case is that it focuses on showing the locations of each individual point, rather than the binned counts, thus it’s more suitable for the purpose of identifying outliers. 
```{r}

ggplot(data = diamonds) +
  geom_point(mapping = aes(x = x, y = y)) +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))

ggplot(data = diamonds) +
  geom_bin2d(mapping = aes(x = x, y = y), bins = 800) +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```