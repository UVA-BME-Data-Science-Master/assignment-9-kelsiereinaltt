---
title: "Assignment 3"
author: "Kelsie Reinaltt"
date: "9/15/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
```

## R Markdown

### ASSIGNMENT 3: EXERCISES IN CHAPTERS 11, 12, 13, 15

### 11.2.2 EXERCISES

## 1. What function would you use to read a file where fields were separated with "|"?

# I would use the read_delim() function where the first argument is the file name that you would like to read in and the second argument is the delimiter that the fields are separated by (in this case the "|").

## 2. Apart from file, skip, and comment, what other arguments do read_csv() and read_tsv() have in common?

```{r}
  union(names(formals(read_csv)), names(formals(read_tsv)))
```

# Other arguments that they have in common include col_names, col_types, locale, na, quoted_na, quote, comment, trim_ws, skip, n_max, guess_max, progress.

## 3. What are the most important arguments to read_fwf()?

# The most important argument to read_fwf() is the col_positions one because it tells where this function to begin and end reading. 

## 4. Sometimes strings in a CSV file contain commas. To prevent them from causing problems they need to be surrounded by a quoting character, like " or '. By convention, read_csv() assumes that the quoting character will be ", and if you want to change it you'll need to use read_delim() instead. What arguments do you need to specify to read the following text into a data frame?

"x,y\n1,'a,b'"

# In order to read this into the data frame, we will have to use read_csv(x,",", quote = "'") - this sets the delimiters as commas and single quotation marks. Additionally, you can also use read_csv(x,quote = "'") because the function already separates out based on commas. 

## 5. Identify what is wrong with each of the following inline CSV files. What happens when you run the code?
#When you run the first line, you get 2 parsing failures. This is because two columns are created (a & b) but then the other inputs have 3 columns (since there are 2 other inputs, you get 2 parsing failures)
# Second line - this sets 3 columns (a, b and c); however, in the second row, there are only two columns and in the third row, there are 4. 
# Third line - this creates a new row ********************8
# Fourth line - *****************8
# Fifth line - the values should be separated by a comma but are instead separated by a semicolon. 
```{r}
read_csv("a,b\n1,2,3\n4,5,6")
read_csv("a,b,c\n1,2\n1,2,3,4")
read_csv("a,b\n\"1")
read_csv("a,b\n1,2\na,b")
read_csv("a;b\n1;3")
```

### 11.3.5 EXERCISES

## 1. What are the most important arguments to locale()?

# Arguments to locale() include date_names, date_format, time_format, decimal_mark, grouping_mark, tz, encoding, asciify. The importance of the arguments depends on what you are trying to do within the locale function (e.g. if you want to change the timezone, you would use the tz argument).

## 2. What happens if you try and set decimal_mark and grouping_mark to the same character? What happens to the default value of grouping_mark when you set decimal_mark to ","? What happens to the default value of decimal_mark when you set the grouping_mark to "."?

# Locale gives you an error if you set decimal mark and grouping mark to the same thing, as shown below. 
# When you set the decimal_mark to "," the grouping_mark is set to "." When you set the grouping mark to ".", the decimal mark is "."

```{r}
locale(decimal_mark = ".", group_mark = ".")
```
```{r}
locale(decimal_mark = ",")
```



## 3. I didn't discuss the date_format and time_format options to locale(). What do they do? Construct an example that shows when they might be useful.

# According to the locale() documentation, the date_format() & time_format() provide the default date and time formats. The time format isn't currently used for anything, but the date format is used when guessing column types. The default date format is %Y-%m-%d. In the readr documentation, they have included an exammple: 
```{r}
parse_date("1 janvier 2015", "%d %B %Y", locale = locale("fr"))
```

## 4. If you live outside the US, create a new locale object that encapsulates the settings for the types of file you read most commonly.

# In India, the locale is written as day, month, year (as opposed to the default which is month, day, year)

```{r}
india_locale <- locale(date_format = "%d/%m/%Y")

```

## 5. What's the difference between read_csv() and read_csv2()?

# read_csv() uses a comma as its delimiter while read_csv2() uses a semicolon as its delimiter. 

## 6. What are the most common encodings used in Europe? What are the most common encodings used in Asia? Do some googling to find out.

# Some of the most common encodings used in Europe include IEC 8859. In Asia, different encodings are used like GB 18030 (primarily in China) and EUC (used primarily in Japan). 
********************

## 7. Generate the correct format string to parse each of the following dates and times:
```{r}
d1 <- "January 1, 2010"
d2 <- "2015-Mar-07"
d3 <- "06-Jun-2017"
d4 <- c("August 19 (2015)", "July 1 (2015)")
d5 <- "12/30/14" # Dec 30, 2014
t1 <- "1705"
t2 <- "11:15:10.12 PM"

read_csv("a,b\n1,2,3\n4,5,6")
read_csv("a,b,c\n1,2\n1,2,3,4")
read_csv("a,b\n\"1")
read_csv("a,b\n1,2\na,b")
read_csv("a;b\n1;3")

parse_date(d1, "%b, %d, %y")
parse_date(d2, "%Y-%b-%d")
parse_date(d3,"%d-%b-%Y")
parse_date(d4,"%B %d (%Y)")
parse_date(d5, "%m/%d/%y")
parse_time(t1,"%H%M")
parse_time(t2, "%H:%M:%OS %p")

```



### 12.2.1 EXERCISES

## 1. Using prose, describe how the variables and observations are organised in each of the sample tables.

# In the sample tables, there are different variables that each have observations within each column (so each variable has a column and each row consists of observations of different variables for a specific country). 
# Table 1 - variables include country, year, cases, population. Observations are in the row and include the year, number of cases and population of each country in that year. 
# Table 2 - variables include country, year, type and count. Observations are organized into rows and include the cases and count for each year and country
# Table 3 - variables include country, year and rate - observations are organized into rows with the corresponding countries and years.
# Table 4a - variables include country and two years. Observations include the country and the number of cases for that country in the two years in this case 1999 & 2000. 
# Table 4b - variables include country and two years; observations are organized to reflect the population in that country/year. 

## 2. Compute the rate for table2, and table4a + table4b. You will need to perform four operations:


```{r}
# Extract the number of TB cases per country per year.

tb_cases <- filter(table2, type == "cases") %>%
  arrange(country, year)

# Extract the matching population per country per year.

matching_population <- filter(table2, type == "population") %>%
  rename(population = count) %>%
  arrange(country, year)

# Divide cases by population, and multiply by 10000.

edited_dataframe = mutate(tb_cases, population = matching_population$population)

with_casesperpopulation = mutate(edited_dataframe, cases_per_population = count/population*10000)

select(with_casesperpopulation, country, year, cases_per_population)

# Store back in the appropriate place.
with_casesperpopulation <- with_casesperpopulation %>%
  mutate(type = "cases_per_population") %>%
  rename(count = cases_per_population)

bind_rows(table2, with_casesperpopulation) %>%
  arrange(country, year, type, count) %>%
  select(country, year, type, count)

```

```{r}
table4c <-
  tibble(country = table4a$country,
         `1999` = table4a[["1999"]] / table4b[["1999"]] * 10000,
       `2000` = table4a[["2000"]] / table4b[["2000"]] * 10000)
table4c
```

## Which representation is easiest to work with? Which is hardest? Why?

# Because no table has both cases and population, they both required extra steps in order to calculate the cases per capita. Thus, they were both relatively similar in terms of difficulty working with. It would be easiest to work with a table that has both cases and population so that we could just use one mutate function to divide and get the correct ratio. 

## 3. Recreate the plot showing change in cases over time using table2 instead of table1. What do you need to do first?

```{r}
table2 %>%
  filter(type == "cases") %>%
  ggplot(aes(year, count)) +
  geom_line(aes(group = country)) +
  geom_point(aes(color = country)) +
  scale_x_continuous(breaks = unique(table2$year)) +
  ylab("cases")
```

### 12.3.3 EXERCISES

## 1. Why are gather() and spread() not perfectly symmetrical?
# Carefully consider the following example:

```{r}
stocks <- tibble(
  year   = c(2015, 2015, 2016, 2016),
  half  = c(   1,    2,     1,    2),
  return = c(1.88, 0.59, 0.92, 0.17)
)
stocks %>% 
  spread(year, return) %>% 
  gather("year", "return", `2015`:`2016`)
# (Hint: look at the variable types and think about column names.)
```
## Both spread() and gather() have a convert argument. What does it do?
************************************************************************

## 2. Why does this code fail?

#table4a %>% 
#  gather(1999, 2000, key = "year", value = "cases")
#> Error in inds_combine(.vars, ind_list): Position must be between 0 and n

#The code fails because 1999 and 2000 are not in quotes - in the current version of the code, 1999 and 2000 are treated as row column numbers which is not the intent of the code (rather, we are looking for years 1999 & 2000). To remedy this, we should put 1999 and 2000 in quotes. 

## 3. Why does spreading this tibble fail? How could you add a new column to fix the problem?

people <- tribble(
  ~name,             ~key,    ~value,
  #-----------------|--------|------
  "Phillip Woods",   "age",       45,
  "Phillip Woods",   "height",   186,
  "Phillip Woods",   "age",       50,
  "Jessica Cordero", "age",       37,
  "Jessica Cordero", "height",   156
)

# Thisfails because there are two rows with Phillip Woods' age. To fix this, we could add a new column that specifies the observation so that we could have two rows with Phillip Woods' age; however, the first would be observation 1 and the second would be observation 2. 

## 4. Tidy the simple tibble below. Do you need to spread or gather it? What are the variables?



# In order to tidy the tibble below , we need to gather it. The variables are pregnant (which can have the observation of either yes or no), sex (which can be either male or female), and count (which counts the number of instances where pregnancies occur in either males or females). 

```{r}
preg <- tribble(
  ~pregnant, ~male, ~female,
  "yes",     NA,    10,
  "no",      20,    12
)
tidied_preg <- preg %>%
  gather(male, female, key = "sex", value = "count", na.rm = TRUE)
tidied_preg

```

### 12.4.3 EXERCISES

## 1. What do the extra and fill arguments do in separate()? Experiment with the various options for the following two toy datasets.

```{r}
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three"))

tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("one", "two", "three"))
```
**************************************

## 2. Both unite() and separate() have a remove argument. What does it do? Why would you set it to FALSE?
# remove() removes the old variable - you would set this to false if you want to create a new variable but keep the old one. 

## 3. Compare and contrast separate() and extract(). Why are there three variations of separation (by position, by separator, and with groups), but only one unite?
****************************************

### 12.5.1 EXERCISES

## 1. Compare and contrast the fill arguments to spread() and complete().

# Spread() allows the user to choose a specific value to replace all missing NA values. However, complete() specifies a list to replace NA values that has specific values for different variables. A similarity includes that both replacec both implicit and explicit missing values. 

## 2. What does the direction argument to fill() do?

# Direction tells you the direction in which to fill missing values (can be down - the default - or up)

### 12.6.1 EXERCISES ************************************************

## 1. In this case study I set na.rm = TRUE just to make it easier to check that we had the correct values. Is this reasonable? Think about how missing values are represented in this dataset. Are there implicit missing values? What's the difference between an NA and zero?

## 2. What happens if you neglect the mutate() step? (mutate(key = stringr::str_replace(key, "newrel", "new_rel")))

## 3. I claimed that iso2 and iso3 were redundant with country. Confirm this claim.

## 4. For each country, year, and sex compute the total number of cases of TB. Make an informative visualisation of the data.

### 13.2.1 EXERCISES 

## 1. Imagine you wanted to draw (approximately) the route each plane flies from its origin to its destination. What variables would you need? What tables would you need to combine?

# flights table: origin and dest
# airports table: longitude and latitude variables
# join flights with airports twice. The first join adds the location of the origin airport (origin). The second join adds the location of destination airport (dest).

## 2. I forgot to draw the relationship between weather and airports. What is the relationship and how should it appear in the diagram?

# faa in airports is matched with origin in weather.

## 3. weather only contains information for the origin (NYC) airports. If it contained weather records for all airports in the USA, what additional relation would it define with flights?

# The variables in each dataset (year/month/day/hour in both, and then origin in weather & dest in flight) would be matched.


## 4. We know that some days of the year are "special", and fewer people than usual fly on them. How might you represent that data as a data frame? What would be the primary keys of that table? How would it connect to the existing tables?

### 13.3.1 EXERCISES

## 1. Add a surrogate key to flights.

## 2. Identify the keys in the following datasets

## 2.1 Lahman::Batting,
## 2.2 babynames::babynames
## 2.3 nasaweather::atmos
## 2.4 fueleconomy::vehicles
## 2.5 ggplot2::diamonds
## (You might need to install some packages and read some documentation.)

## 3. Draw a diagram illustrating the connections between the Batting, Master, and Salaries tables in the Lahman package. Draw another diagram that shows the relationship between Master, Managers, AwardsManagers.

## How would you characterise the relationship between the Batting, Pitching, and Fielding tables?

### 13.4.6 EXERCISES 
## 1. Compute the average delay by destination, then join on the airports data frame so you can show the spatial distribution of delays. Here's an easy way to draw a map of the United States:

airports %>%
  semi_join(flights, c("faa" = "dest")) %>%
  ggplot(aes(lon, lat)) +
    borders("state") +
    geom_point() +
    coord_quickmap()
## (Don't worry if you don't understand what semi_join() does - you'll learn about it next.)

## You might want to use the size or colour of the points to display the average delay for each airport.

## 2. Add the location of the origin and destination (i.e. the lat and lon) to flights.

## 3. Is there a relationship between the age of a plane and its delays?

## 4. What weather conditions make it more likely to see a delay?

## 5. What happened on June 13 2013? Display the spatial pattern of delays, and then use Google to cross-reference with the weather.

### 13.5.1 EXERCISES
## 1. What does it mean for a flight to have a missing tailnum? What do the tail numbers that don't have a matching record in planes have in common? (Hint: one variable explains ~90% of the problems.)

## 2. Filter flights to only show flights with planes that have flown at least 100 flights.

## 3. Combine fueleconomy::vehicles and fueleconomy::common to find only the records for the most common models.

## 4. Find the 48 hours (over the course of the whole year) that have the worst delays. Cross-reference it with the weather data. Can you see any patterns?

## 5. What does anti_join(flights, airports, by = c("dest" = "faa")) tell you? What does anti_join(airports, flights, by = c("faa" = "dest")) tell you?

## 6. You might expect that there's an implicit relationship between plane and airline, because each plane is flown by a single airline. Confirm or reject this hypothesis using the tools you've learned above.

### 15.3.1 EXERCISES 
## 1. Explore the distribution of rincome (reported income). What makes the default bar chart hard to understand? How could you improve the plot?

## 2. What is the most common relig in this survey? What's the most common partyid?

## 3. Which relig does denom (denomination) apply to? How can you find out with a table? How can you find out with a visualisation?

### 15.4.1 EXERCISES
## 1. There are some suspiciously high numbers in tvhours. Is the mean a good summary?

## 2. For each factor in gss_cat identify whether the order of the levels is arbitrary or principled.

## 3. Why did moving "Not applicable" to the front of the levels move it to the bottom of the plot?

### 15.5.1 EXERCISES
## 1. How have the proportions of people identifying as Democrat, Republican, and Independent changed over time?

## 2. How could you collapse rincome into a small set of categories?